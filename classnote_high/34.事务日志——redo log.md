事务有四种特性: 原子性、一致性、隔离性、持久性,其中事务的隔离性由锁机制实现,而事务的原子性、一致性和持久性由事务的redo日志和undo日志来保证;

1.事务日志
    - redo log称为重做日志,提供再写入操作,恢复提交事务修改的页操作,用来保证事务的持久性;
    - undo log称为回滚日志,回滚行记录到某个特定的版本,用来保证事务的原子性、一致性;
    　
    undo并非是redo的逆过程,二者都可以被视为是一种恢复操作,但是
    - redo log:是存储引擎层(Innodb)生成的日志,记录的是"物理级别"上的页的修改操作,比如页号12,偏移量300写入了"buck"数据,主要是为了
    保证数据的可靠性、持久性;
    - undo log:是存储引擎层(Innodb)生成的日志,记录的是逻辑操作日志,比如对某一行数据进行了INSERT语句操作,那么undo log就记录一条
    与之相反的DELETE操作,主要用于事务的回滚(undo log记录的是每个修改操作的逆操作)和一致性非锁定读(undo log回滚行记录到某种特定的
    版本————MVCC,即多版本并发控制

2.redo日志
    为什么需要redo日志?
        一方面因为我们目前在操作数据库时都是先将数据从磁盘读入内存,在内存中进行操作,操作后在将内存中修改的内容写入磁盘,那么就存在着一种情况,即
      我们刚把数据写入内存,还未刷盘,服务挂掉了,那么数据就丢失了,无法恢复;
        另一方面,事务包含持久性的特性,对于一个已经提交的事务,在事务提交后即使系统崩溃,那么该事务对于数据库的改动也不能丢失;
　
    为什么我们不选择在事务提交完成之前,先将该事务做的所有修改都刷新到磁盘呢?
        这是一种很粗暴的方式,诚然可以保证数据持久性,但是还存在着一些问题;
        首先,有时候我们仅仅会修改某个页中的一个字节,但是我们知道InnoDB中是以页为单位进行磁盘IO的,也就是说我们在该事务提交前必须要将整个页刷新到
      磁盘,我们一个页默认是16KB,那我们为了一个字节就要刷新16KB的数据到磁盘未免显得太过小题大做;
        其次,一个事务可能包含很多语句,即使是一条语句也可能修改的数据分布在多个页,那如果这些页并不相邻,那么此时的刷盘需要进行很多的随机IO,随机IO
      相较于顺序IO是非常慢的;
　
    [InnoDB引擎的事务采用了WAL技术(Write-Ahead Logging),这种技术的思想就是先写日志,在写磁盘,只有日志写入成功,才算事务成功,这里的日志就是redo log;
  当发生宕机且数据未刷到磁盘的时候,可以通过redo log来恢复,保证ACID中的D——持久性,这就是redo log的作用]
    　
    redo log的好处？
      - 降低了刷盘频率(无需每一次微小改动即刻刷盘,而是会将这些改动写入redo log,1s后再根据redo log里的记录进行刷盘)
      - redo log日志占用的空间非常小(redo log中只记录了存储表空间ID、页号、偏移量以及需要更新的值,所需的存储空间是很小的,刷盘快)
　
    redo log的特点    
      - redo log是顺序写入磁盘的(在执行事务的过程中,每执行一条语句,就可能产生若干条redo日志,这些日志是按照产生的顺序写入磁盘的,也就是使用顺序IO,效率比随机IO快);
      - redo log会在事务执行过程中不断记录(这个特点就需要与一个我们之后会再学习的binlog进行对比,redo log是存储引擎层产生的,而bin log是数据库层产生的;假设一个
        事务,对表做10w行的记录插入,在这个过程中,一直不断的往redo log顺序记录,而bin log在这个过程中不会记录,直到这个事务提交,才会一次性写入bin log文件中)
　
    redo的组成
      - 重做日志缓冲 redo log buffer,保存在内存中,是易失的,默认大小16M,最大值是4096M,最小值是1M
      - 重做日志文件 redo log file,保存在硬盘中,是持久的
　
    redo log的整体流转过程
      1)先将原始数据从磁盘中读入内存,修改数据的内存拷贝
      2)生成一条重做日志并写入redo log buffer,记录的是数据被修改后的值
      3)当事务commit时,将redo log buffer中的内容刷新到redo log file,对redo log file采用追加写的方式
      4)定期根据redo log file,将内存中修改的数据刷新到磁盘中
　
    redo log的刷盘策略
        redo log的写入并不是直接写入磁盘,它由两部分构成,InnoDB引擎会在写redo log的时候先写redo log buffer,之后以一定的频率刷入到真正的redo log file中;
      这里的一定频率怎么看待呢?这个过程(redo log buffer -> redo log file)就是我们要说的刷盘策略;
        首先需要注意,redo log buffer刷盘到redo log file的过程并不是真正的刷到磁盘中,只是刷到文件系统缓存(page cache)中去,这是现代操作系统为了提高文件写入效率
      做的一个优化,真正的写入会交给系统自己来决定(比如page cache足够大了);那么对于InnoDB来说就存在一个问题,如果交给系统来同步,如果系统宕机了呢？数据就会丢失了,虽然
      整个操作系统宕机的可能性还是比较小的;
        针对这种情况,InnoDB给出innodb_flush_log_at_trx_commit参数,该参数控制commit提交事务时,如何将redo log buffer中的日志刷新到redo log file中,
      它支持三种策略:
          - 设置为0: 表示每次事务提交时不进行刷盘操作(系统默认master thread每隔1s进行一次重做日志的同步)
          - 设置为1: 表示每次事务提交都将进行同步,刷盘(该情况也是目前innodb的默认情况)
          - 设置为2: 表示每次事务提交时都只把redo log buffer内容写入page cache,不进行同步,有OS自己决定什么时候同步到磁盘;
        Obvious,第一种是最不安全的,因为mysql宕机的可能性相对于操作系统来说还是要更大,第三种稍微安全点,但是如果操作系统宕机,那么当时page cache中的数据就会丢失,
      第二种是最安全的,虽然也是最慢的,但是事务本身对于数据一致性和持久化要求非常高,所以在innodb中默认还是选择了该情况,可以最大程度的保证数据不丢失;
　
    写入redo log buffer的过程(了解即可)
        补充概念: Mini-Transaction,Mysql把对底层页面中的一次原子访问的过程称之为一个Mini-Transaction,简称mtr,比如,向某个索引对应的B+树中插入一条记录的过程
      就是一个mtr,一个mtr可以包含一组redo日志(因为即使一条简单的插入命令,对于数据的偏移也可能是多个,加入你要在a和c之间插入b,那其实你要记录的不光是b的变动,还有c)
      在进行崩溃恢复时这一组redo日志作为一个不可分割的整体;一个事务可以包含若干条语句,每条语句其实有由若干个mtr组成,每一个mtr又可以包含多条redo日志;
        向redo log buffer中写入redo日志的过程是顺序的,先往前面的block中写,当该block的空闲空间用完后,再往下一个block中写,当我们想往log buffer中写入redo日志时,
      第一个遇到的问题就是应该写在哪个block的哪个偏移量处,为此,Innodb设计者提供了一个称为buf_free的全局变量,用来指明后续写入的redo日志应该写到log buffer中的哪个位置;
        如果多个事务并发运行,此时多个事务会产生多个mtr,这些mtr的插入顺序是不确定的,可能先插入一个事务1的mtr_1_1,又插入了一个事务2的mtr_2_1,又插入了一个事务1的mtr_1_2,
      但是每个mtr包含的多个redo是不会跟其他mtr的redo出现交叉写入的情况的,这点需要知晓;
　
    redo log file相关概念
        - 日志文件组,即我们的redo log file并不只是一个文件,而是多个文件,具体有几个,由参数:innodb_log_files_in_group决定;
        InnoDB中是采用多个日志文件顺序循环存储数据的模式,并用checkpoint和write pos来进行点位的记录,
        举例来说,我们当前的日志文件组中4个redo log file,分别是file0,file1,file2,file3,那么根据我们顺序循环存储的原则,此时数据会优先存入file0,
      那么此时write pos就会指向当前数据写入后的位置,write pos用来标识下一次文件写入的位置,后续的数据会陆续存入file1,file2,此刻到了刷盘时间,
      假设现在将file0和file1的数据刷盘,那么此时checkpoint就会指向file1末尾的位置,checkpoint记录下一次要进行刷盘的位置,接下来继续插入数据,
      很快file3也被存满了,根据顺序循环插入的原则,现在要回头向file0中插入数据了,可是file0中已有数据,还可以插吗？可以,因为file0中的数据已经刷盘完成,
      实际上是无用数据,所以覆盖,file1亦然,但当数据插入的file1末尾位置,即write pos和checkpoint交汇,那就代表我们的日志文件组已经满了,现在只能等待
      下一次刷盘,或者考虑扩容,无法继续插入了;